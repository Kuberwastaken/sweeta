{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# üç¨ Sweeta - SORA 2 Watermark Remover\n",
        "\n",
        "### Remove watermarks from SORA 2 video generations\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-kuberwastaken/sweeta-pink?logo=github)](https://github.com/kuberwastaken/sweeta)\n",
        "[![License](https://img.shields.io/badge/License-Apache%202.0-pink.svg)](https://github.com/kuberwastaken/sweeta/blob/main/LICENSE)\n",
        "\n",
        "---\n",
        "\n",
        "**What this does:** Removes watermarks from SORA 2 generated videos using AI\n",
        "\n",
        "**Runtime:** ~5-15 minutes depending on video length\n",
        "---\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è Important Disclaimer\n",
        "\n",
        "**FOR EDUCATIONAL AND RESEARCH PURPOSES ONLY**\n",
        "\n",
        "This tool is provided to:\n",
        "- Demonstrate AI capabilities in computer vision\n",
        "- Encourage OpenAI to implement stronger watermarking\n",
        "- Research watermark removal techniques\n",
        "\n",
        "**Please use responsibly and ethically. Respect content creator rights and intellectual property.**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instructions\n",
        "\n",
        "Follow these steps in order:\n",
        "\n",
        "1. **Step 1:** Enable GPU runtime (Runtime ‚Üí Change runtime type ‚Üí T4 GPU)\n",
        "2. **Step 2:** Run the setup cell (installs conda)\n",
        "3. **Step 3:** Clone the Sweeta repository\n",
        "4. **Step 4:** Upload your SORA 2 video\n",
        "5. **Step 5:** Process the video\n",
        "6. **Step 6:** Download your watermark-free video\n",
        "\n",
        "‚è±Ô∏è **Total time:** ~5-15 minutes\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Check GPU Status\n",
        "\n",
        "Let's make sure you have GPU enabled! This should show your GPU info.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "!nvidia-smi -L\n",
        "print(\"\\n‚úÖ GPU detected! You're good to go.\")\n",
        "print(\"\\n‚ö†Ô∏è If you see an error above, go to: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Conda\n",
        "\n",
        "This installs conda (a package manager) which is needed for the project.\n",
        "\n",
        "**Time:** ~30 seconds\n",
        "\n",
        "**‚ö†Ô∏è Note:** The kernel will restart after this step. That's normal!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install condacolab (required for conda in Colab)\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "print(\"Conda installed successfully!\")\n",
        "print(\"Kernel will restart automatically...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone Sweeta Repository\n",
        "\n",
        "This downloads the Sweeta code from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Clone the repository\n",
        "if not os.path.exists('/content/Sweeta'):\n",
        "    print(\" Cloning Sweeta repository...\")\n",
        "    !git clone https://github.com/kuberwastaken/Sweeta.git\n",
        "    print(\"\\n‚úÖ Repository cloned successfully!\")\n",
        "else:\n",
        "    print(\"‚úÖ Repository already exists!\")\n",
        "\n",
        "# Change to the project directory\n",
        "%cd /content/Sweeta\n",
        "print(\"\\nüìÇ Current directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Install Dependencies\n",
        "\n",
        "This sets up the Python environment and downloads the AI model.\n",
        "\n",
        "**What's happening:**\n",
        "- Creating Python 3.12 environment\n",
        "- Installing required packages (PyTorch, transformers, etc.)\n",
        "- Downloading LaMA inpainting model (~200MB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environment directly\n",
        "print(\"üîß Setting up environment...\\n\")\n",
        "\n",
        "# Create conda environment from environment.yml\n",
        "print(\"üì¶ Creating conda environment...\")\n",
        "!conda env create -f environment.yml\n",
        "\n",
        "# Activate and install additional dependencies\n",
        "print(\"\\nüì¶ Installing additional packages...\")\n",
        "!conda run -n py312aiwatermark pip install PyQt6 transformers opencv-python-headless\n",
        "\n",
        "# Set HuggingFace cache directory to avoid permission issues\n",
        "import os\n",
        "os.environ['HF_HOME'] = '/content/hf_cache'\n",
        "os.environ['TORCH_HOME'] = '/content/torch_cache'\n",
        "\n",
        "# Download the LaMA model with proper error handling\n",
        "print(\"\\nüì• Downloading LaMA model (this may take a few minutes)...\")\n",
        "try:\n",
        "    !conda run -n py312aiwatermark python -c \"from iopaint.model_manager import ModelManager; from iopaint.schema import HDStrategy; ModelManager(name='lama', device='cpu')\"\n",
        "    print(\"‚úÖ LaMA model downloaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Alternative download method...\")\n",
        "    # Fallback: Initialize ModelManager which will auto-download on first use\n",
        "    !conda run -n py312aiwatermark pip install --upgrade huggingface-hub\n",
        "    !conda run -n py312aiwatermark python -c \"from iopaint.model_manager import ModelManager; ModelManager(name='lama', device='cpu')\"\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies installed!\")\n",
        "print(\"\\nüéâ Setup complete! Ready to process videos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Upload Your SORA 2 Video\n",
        "\n",
        "Click the **\"Choose Files\"** button below to upload your video.\n",
        "\n",
        "**Supported formats:** MP4, AVI, MOV, MKV\n",
        "\n",
        "**Note:** Large files may take a while to upload. Be patient!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Please select your SORA 2 video file...\\n\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded filename\n",
        "input_video = list(uploaded.keys())[0]\n",
        "print(f\"\\n‚úÖ Uploaded: {input_video}\")\n",
        "print(f\"üìä File size: {os.path.getsize(input_video) / (1024*1024):.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== CUSTOMIZE THESE SETTINGS =====\n",
        "\n",
        "# Detection sensitivity (1-100, lower = more aggressive)\n",
        "max_bbox_percent = 15  # Good for SORA 2 watermarks\n",
        "\n",
        "# Output format (MP4, AVI, WEBM, MOV)\n",
        "output_format = \"MP4\"\n",
        "\n",
        "# Make watermarks transparent instead of inpainting (slower)\n",
        "transparent = False\n",
        "\n",
        "# Output filename\n",
        "output_video = \"output_no_watermark.mp4\"\n",
        "\n",
        "# ====================================\n",
        "\n",
        "print(\" Configuration:\")\n",
        "print(f\"   üìä Max BBox Percent: {max_bbox_percent}%\")\n",
        "print(f\"   üìπ Output Format: {output_format}\")\n",
        "print(f\"   üé® Transparent Mode: {transparent}\")\n",
        "print(f\"   üíæ Output File: {output_video}\")\n",
        "print(\"\\n‚úÖ Configuration ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 6: Process Video\n",
        "\n",
        "This is where the magic happens! The AI will:\n",
        "1. Extract frames from your video\n",
        "2. Detect watermarks in each frame\n",
        "3. Remove watermarks using inpainting\n",
        "4. Reassemble into a video\n",
        "\n",
        "**Tip:** You'll see progress updates below. Don't close the tab!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import subprocess\n",
        "import threading\n",
        "import sys\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"üöÄ Starting video processing...\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Build the command - directly call Python script with conda\n",
        "transparent_flag = \"--transparent\" if transparent else \"\"\n",
        "overwrite_flag = \"--overwrite\"\n",
        "\n",
        "# Make sure we're in the right directory\n",
        "%cd /content/Sweeta\n",
        "\n",
        "print(f\"üìπ Processing: {input_video}\")\n",
        "print(f\"üìÅ Output: {output_video}\")\n",
        "print(f\"‚öôÔ∏è Settings: max_bbox_percent={max_bbox_percent}, format={output_format}\")\n",
        "print(f\"üîß Flags: {transparent_flag} {overwrite_flag}\")\n",
        "print(\"\\nüí° This may take 5-15 minutes depending on video length...\")\n",
        "print(\"‚è≥ Processing frames (this will show progress when available)...\\n\")\n",
        "\n",
        "# Build the full command\n",
        "cmd = [\n",
        "    \"conda\", \"run\", \"-n\", \"py312aiwatermark\", \"python\", \"remwm.py\",\n",
        "    f\"/content/Sweeta/{input_video}\",\n",
        "    f\"/content/Sweeta/{output_video}\",\n",
        "    \"--max-bbox-percent\", str(max_bbox_percent),\n",
        "    \"--force-format\", output_format,\n",
        "]\n",
        "\n",
        "# Add optional flags\n",
        "if transparent:\n",
        "    cmd.append(\"--transparent\")\n",
        "cmd.append(\"--overwrite\")\n",
        "\n",
        "print(f\"üîç Running command: {' '.join(cmd)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Run with real-time output\n",
        "process = subprocess.Popen(\n",
        "    cmd,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    universal_newlines=True,\n",
        "    bufsize=1\n",
        ")\n",
        "\n",
        "# Print output in real-time\n",
        "try:\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            print(output.strip())\n",
        "            sys.stdout.flush()\n",
        "        \n",
        "        # Check if process is taking too long (30 minutes timeout)\n",
        "        if time.time() - start_time > 1800:  # 30 minutes\n",
        "            print(\"\\n‚ö†Ô∏è Process taking longer than 30 minutes. This might be normal for very long videos.\")\n",
        "            print(\"üí° You can wait longer or restart if needed.\")\n",
        "            break\n",
        "            \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nüõë Process interrupted by user\")\n",
        "    process.terminate()\n",
        "\n",
        "# Wait for process to complete\n",
        "return_code = process.poll()\n",
        "if return_code is None:\n",
        "    return_code = process.wait()\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"=\"*60)\n",
        "\n",
        "if return_code == 0:\n",
        "    print(f\"\\n‚úÖ Processing complete!\")\n",
        "    print(f\"‚è±Ô∏è Time taken: {elapsed_time/60:.2f} minutes\")\n",
        "    print(f\"üìÅ Output saved to: {output_video}\")\n",
        "    \n",
        "    # Check if output file exists and show size\n",
        "    import os\n",
        "    if os.path.exists(output_video):\n",
        "        size_mb = os.path.getsize(output_video) / (1024*1024)\n",
        "        print(f\"üìä Output file size: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Warning: Output file not found!\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå Processing failed with return code: {return_code}\")\n",
        "    print(\"üí° Check the output above for error details\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Download Your Video\n",
        "\n",
        "Your watermark-free video is ready! Click the download link below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if processing is still running\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "print(\"üîç System Status Check:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check GPU memory\n",
        "print(\"üìä GPU Memory Usage:\")\n",
        "!nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits\n",
        "\n",
        "# Check if python processes are running\n",
        "print(\"\\nüêç Python Processes:\")\n",
        "for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
        "    try:\n",
        "        if 'python' in proc.info['name'].lower() and 'remwm' in ' '.join(proc.info['cmdline']):\n",
        "            print(f\"   PID {proc.info['pid']}: {' '.join(proc.info['cmdline'][:3])}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# Check if output file is being created/updated\n",
        "print(f\"\\nüìÅ Output File Status:\")\n",
        "if os.path.exists(output_video):\n",
        "    size = os.path.getsize(output_video)\n",
        "    print(f\"   ‚úÖ {output_video} exists ({size} bytes)\")\n",
        "    if size > 0:\n",
        "        print(\"   üìà File is growing - processing is likely working!\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è File is empty - processing may have just started\")\n",
        "else:\n",
        "    print(f\"   ‚ùå {output_video} not found yet\")\n",
        "\n",
        "# Check temp files (processing might create temporary files)\n",
        "print(f\"\\nüóÇÔ∏è Temporary Files:\")\n",
        "temp_files = [f for f in os.listdir('.') if f.startswith('tmp') or 'temp' in f.lower()]\n",
        "if temp_files:\n",
        "    for f in temp_files[:5]:  # Show first 5\n",
        "        print(f\"   üìÑ {f}\")\n",
        "else:\n",
        "    print(\"   No temp files found\")\n",
        "\n",
        "print(\"\\nüí° If you see GPU usage and/or temp files, processing is likely working!\")\n",
        "print(\"üí° Video processing can take 10-30+ minutes for longer videos.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì• Step 7: Download Your Video\n",
        "\n",
        "Your watermark-free video is ready! Click the download link below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "if os.path.exists(output_video):\n",
        "    print(\"üì• Downloading your video...\\n\")\n",
        "    files.download(output_video)\n",
        "    print(\"\\n‚úÖ Download started! Check your browser's download folder.\")\n",
        "    print(f\"üìä Output file size: {os.path.getsize(output_video) / (1024*1024):.2f} MB\")\n",
        "else:\n",
        "    print(\"‚ùå Error: Output file not found!\")\n",
        "    print(\"Please check the processing step for errors.\")\n",
        "    print(\"\\nüí° Try running the status check cell above to see what's happening.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Troubleshooting\n",
        "\n",
        "### Common Issues:\n",
        "\n",
        "**‚ùå \"CUDA out of memory\" error**\n",
        "- Solution: Try processing a shorter video or restart runtime\n",
        "\n",
        "**‚ùå \"ModuleNotFoundError\" or import errors**\n",
        "- Solution: Re-run Step 3 (Install Dependencies)\n",
        "\n",
        "**‚ùå Watermarks not fully removed**\n",
        "- Solution: Try lowering `max_bbox_percent` to 10 or 5\n",
        "- Alternative: Enable `transparent = True` mode\n",
        "\n",
        "**‚ùå Video quality degraded**\n",
        "- Solution: Try a different output format (MP4 ‚Üí AVI)\n",
        "- Check if original video had high quality\n",
        "\n",
        "**‚ùå Processing takes too long**\n",
        "- Note: Long videos take time. A 60s video can take 15+ minutes\n",
        "- Tip: Process shorter clips for faster results\n",
        "\n",
        "### Still having issues?\n",
        "\n",
        "- üêõ [Open an issue on GitHub](https://github.com/kuberwastaken/sweeta/issues)\n",
        "- üìß Contact: [Twitter @kuberwastaken](https://twitter.com/kuberwastaken)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## About This Project\n",
        "\n",
        "### Credits:\n",
        "- Built by [Kuber Mehta](https://kuber.studio/)\n",
        "- Based on WatermarkRemover-AI by D-Ogi\n",
        "- Development journey: [journal.md](https://github.com/kuberwastaken/sweeta/blob/main/journal.md)\n",
        "\n",
        "### Links:\n",
        "[GitHub Repository](https://github.com/kuberwastaken/sweeta), [Documentation](https://github.com/kuberwastaken/sweeta#readme), [Twitter @kuberwastaken](https://twitter.com/kuberwastaken)\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**Use only for Educational and Research Purposes**\n",
        "\n",
        "[Star on GitHub](https://github.com/kuberwastaken/sweeta) if you found this useful!\n",
        "\n",
        "**License:** Apache 2.0 | **Use responsibly and ethically**\n",
        "\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
